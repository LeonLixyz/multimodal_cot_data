{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an expert in creating clean multimodal chain of thought traces. Your task is to first analyze a raw and noisy reasoning trace along with associated images, and then generate a clean, structured, step-by-step multimodal reasoning trace that solves the original problem.\n",
            "\n",
            "**Input Data Provided to You:**\n",
            "The input data has the following components:\n",
            "- Problem & Noisy Trace Context: A JSON structure representing a noisy or raw interleaved text and image reasoning trace. Image data within this structure will be represented by placeholders (e.g., `[input_image]`, `[intermediate_image_1]`).\n",
            "- Image Data: The actual image data (input image and any intermediate images generated during the noisy trace) corresponding to the placeholders, provided separately.\n",
            "\n",
            "**Your Task:** Generate a *new*, clean JSON output trace that represents the *ideal* multimodal reasoning process to solve the problem, using the provided context and images for understanding. Ensure the reasoning is logically coherent and clearly explained.\n",
            "\n",
            "**Output Format (Clean Trace with Placeholders):**\n",
            "You MUST generate a valid JSON array adhering strictly to the following structure. Use the specified placeholders for images:\n",
            "[\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"type\": \"text\", \n",
            "        \"text\": \"The original problem statement\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"image_url\",\n",
            "        \"image_url\": {\n",
            "          \"url\": \"[input_image]\" // use this placeholder for the input image, DO NOT use base64 for your output\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"type\": \"text\", \n",
            "        \"text\": \"THOUGHT 0: <Clear description of initial reasoning step>\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"text\", \n",
            "        \"text\": \"THOUGHT 1: <Clear description of the next reasoning step, often explaining why an image will be created>\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"image_url\",\n",
            "        \"image_url\": {\n",
            "          \"url\": \"[intermediate_image_1]\" // use this placeholder for subsequent intermediate images, DO NOT use base64 for your output\n",
            "        }\n",
            "      },\n",
            "      // ... Add more text thoughts and image placeholders as needed for logical flow ...\n",
            "      {\n",
            "        \"type\": \"image_url\",\n",
            "        \"image_url\": {\n",
            "          \"url\": \"[intermediate_image_X]\" // Placeholder for subsequent intermediate images\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"text\",\n",
            "        \"text\": \"THOUGHT N: <Description of the final reasoning step before the answer>\"\n",
            "      },\n",
            "      {\n",
            "        \"type\": \"text\", \n",
            "        \"text\": \"ANSWER: <The final calculated answer based on the reasoning>\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n",
            "\n",
            "**Key Guidelines for Generation:**\n",
            "\n",
            "1.  Generate Coherent Reasoning: Focus on creating a logically sound step-by-step thought process that correctly solves the problem, using the provided images and context trace for understanding.\n",
            "\n",
            "2.  Use Placeholders for Images: Represent **all** images in the generated JSON using placeholders: `[input_image]` for the initial problem image and `[intermediate_image_X]` (e.g., `[intermediate_image_1]`, `[intermediate_image_2]`) for images generated during the reasoning process.\n",
            "\n",
            "3. Remove technical debugging information, code details, or observations unless they directly explain reasoning\n",
            "\n",
            "4. Avoid including noise from the original trace (code, errors, verbose observations) unless mentioning a concept from it is essential for the clean reasoning.\n",
            "\n",
            "5. Keep the original problem statement and initial image\n",
            "\n",
            "6. Keep the original auxiliary images in the raw reasoning trace\n",
            "\n",
            "7. Maintain the logical flow and numbered thought sequence\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "# read the json file\n",
        "with open('system.json', 'r') as f:\n",
        "    template = json.load(f)\n",
        "\n",
        "# print the data\n",
        "print(template[\"prompt_template\"])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vlm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
