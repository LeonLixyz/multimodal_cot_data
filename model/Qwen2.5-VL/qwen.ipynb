{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/al4263/.conda/envs/llm_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import BaseModelOutputWithPast, ModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "@dataclass\n",
    "class Qwen2_5_VLCausalLMOutputWithPast(ModelOutput):\n",
    "    \"\"\"\n",
    "    Base class for Qwen2_5_VL causal language model (or autoregressive) outputs.\n",
    "\n",
    "    Args:\n",
    "        loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided):\n",
    "            Language modeling loss (for next-token prediction).\n",
    "        logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`):\n",
    "            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
    "        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n",
    "            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n",
    "            `(batch_size, num_heads, sequence_length, embed_size_per_head)`)\n",
    "\n",
    "            Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see\n",
    "            `past_key_values` input) to speed up sequential decoding.\n",
    "        hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n",
    "            Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
    "            one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
    "\n",
    "            Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n",
    "        attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n",
    "            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
    "            sequence_length)`.\n",
    "\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "        rope_deltas (`torch.LongTensor` of shape `(batch_size, )`, *optional*):\n",
    "            The rope index difference between sequence length and multimodal rope.\n",
    "    \"\"\"\n",
    "\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    past_key_values: Optional[List[torch.FloatTensor]] = None\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    rope_deltas: Optional[torch.LongTensor] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.38it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    cache_dir=HF_HOME_DIR,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "# The default range for the number of visual tokens per image in the model is 4-16384.\n",
    "# You can set min_pixels and max_pixels according to your needs, such as a token range of 256-1280, to balance performance and cost.\n",
    "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)\n",
    "\n",
    "# messages = [\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": [\n",
    "#             {\n",
    "#                 \"type\": \"image\",\n",
    "#                 \"image\": \"latex.png\",\n",
    "#                 \"min_pixels\": 4*28*28,\n",
    "#                 \"max_pixels\": 4*28*28,\n",
    "#             },\n",
    "#             {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "#         ],\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # Preparation for inference\n",
    "# text = processor.apply_chat_template(\n",
    "#     messages, tokenize=False, add_generation_prompt=True\n",
    "# )\n",
    "# image_inputs, video_inputs = process_vision_info(messages)\n",
    "# inputs = processor(\n",
    "#     text=[text],\n",
    "#     images=image_inputs,\n",
    "#     videos=video_inputs,\n",
    "#     padding=True,\n",
    "#     return_tensors=\"pt\",\n",
    "# )\n",
    "# inputs = inputs.to(\"cuda\")\n",
    "\n",
    "# # # Inference: Generation of the output\n",
    "# generated_ids = model.generate(**inputs, max_new_tokens=512)\n",
    "# generated_ids_trimmed = [\n",
    "#     out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "# ]\n",
    "# output_text = processor.batch_decode(\n",
    "#     generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "# )\n",
    "# print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMG_TOKENS = 512\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe these images?\"},\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": \"latex.png\",\n",
    "                \"min_pixels\": N_IMG_TOKENS*28*28,\n",
    "                \"max_pixels\": N_IMG_TOKENS*28*28,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": \"latex_2.png\",\n",
    "                \"min_pixels\": N_IMG_TOKENS*28*28,\n",
    "                \"max_pixels\": N_IMG_TOKENS*28*28,\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"These are from my notes.\"},\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = processor.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, add_vision_id=True\n",
    ")\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "inputs = inputs.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: 151644 decoded: <|im_start|>\n",
      "token: 8948 decoded: system\n",
      "token: 198 decoded: \n",
      "\n",
      "token: 2610 decoded: You\n",
      "token: 525 decoded:  are\n",
      "token: 264 decoded:  a\n",
      "token: 10950 decoded:  helpful\n",
      "token: 17847 decoded:  assistant\n",
      "token: 13 decoded: .\n",
      "token: 151645 decoded: <|im_end|>\n",
      "token: 198 decoded: \n",
      "\n",
      "token: 151644 decoded: <|im_start|>\n",
      "token: 872 decoded: user\n",
      "token: 198 decoded: \n",
      "\n",
      "token: 6713 decoded: Can\n",
      "token: 498 decoded:  you\n",
      "token: 7512 decoded:  describe\n",
      "token: 1493 decoded:  these\n",
      "token: 5335 decoded:  images\n",
      "token: 30 decoded: ?\n",
      "token: 151652 decoded: <|vision_start|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151653 decoded: <|vision_end|>\n",
      "token: 151652 decoded: <|vision_start|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151655 decoded: <|image_pad|>\n",
      "token: 151653 decoded: <|vision_end|>\n",
      "token: 9485 decoded: These\n",
      "token: 525 decoded:  are\n",
      "token: 504 decoded:  from\n",
      "token: 847 decoded:  my\n",
      "token: 8388 decoded:  notes\n",
      "token: 13 decoded: .\n",
      "token: 151645 decoded: <|im_end|>\n",
      "token: 198 decoded: \n",
      "\n",
      "token: 151644 decoded: <|im_start|>\n",
      "token: 77091 decoded: assistant\n",
      "token: 198 decoded: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence = inputs['input_ids'].tolist()[0]\n",
    "\n",
    "decoded_text = processor.tokenizer.decode(sequence)\n",
    "for i in range(len(sequence)):\n",
    "    print('token:', sequence[i], 'decoded:', processor.tokenizer.decode([sequence[i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "class AnyToAnyQwen2_5_VL(Qwen2_5_VLForConditionalGeneration):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # Number of vision tokens to generate after <|vision_start|>\n",
    "        self.n_img_tokens = 10  # Assuming 10 image embeddings as mentioned in requirements\n",
    "        # Special token IDs\n",
    "        self.vision_start_token_id = 151652  # <|vision_start|>\n",
    "        self.vision_end_token_id = 151653    # <|vision_end|>\n",
    "        # Setup vision head\n",
    "        self.setup_vision_head()\n",
    "        # Initialize weights\n",
    "        self.post_init()\n",
    "\n",
    "    def setup_vision_head(self):\n",
    "        \"\"\"Initialize the vision head that predicts vision embeddings.\"\"\"\n",
    "        self.vision_head = nn.Linear(self.config.hidden_size, self.config.hidden_size, bias=False)\n",
    "\n",
    "    def generate_labels(self, input_ids, vision_positions=None):\n",
    "        \"\"\"\n",
    "        Generate labels for language modeling (same as input_ids for next-token prediction).\n",
    "        Masks out vision positions with -100 so they don't contribute to text loss.\n",
    "        \"\"\"\n",
    "        labels = input_ids.clone()\n",
    "        \n",
    "        # Mask out vision positions\n",
    "        if vision_positions is not None:\n",
    "            labels = labels.masked_fill(vision_positions, -100)\n",
    "        \n",
    "        print(f\"labels: {labels}, shape: {labels.shape}\")\n",
    "        print(f\"vision_positions: {vision_positions}, shape: {vision_positions.shape}\")\n",
    "        \n",
    "        return labels\n",
    "        \n",
    "    def identify_vision_positions(self, input_ids):\n",
    "        \"\"\"\n",
    "        Create a boolean mask identifying positions where vision tokens should be predicted.\n",
    "        These positions include:\n",
    "        1. Image token positions (marked by self.config.image_token_id)\n",
    "        2. Positions between vision_start_token_id and vision_end_token_id\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Tensor of shape (batch_size, seq_length)\n",
    "            \n",
    "        Returns:\n",
    "            is_vision_position: Boolean mask of shape (batch_size, seq_length)\n",
    "        \"\"\"\n",
    "        # First identify positions with image_token_id\n",
    "        is_vision_position = (input_ids == self.config.image_token_id)\n",
    "        \n",
    "        # Also identify positions with video_token_id if applicable\n",
    "        if hasattr(self.config, 'video_token_id'):\n",
    "            is_vision_position = is_vision_position | (input_ids == self.config.video_token_id)\n",
    "        \n",
    "        # Next, identify positions between vision_start_token_id and vision_end_token_id\n",
    "        batch_size, seq_length = input_ids.shape\n",
    "        \n",
    "        # Find positions where we need to predict vision tokens\n",
    "        for b in range(batch_size):\n",
    "            # Find start tokens in the sequence\n",
    "            starts = (input_ids[b] == self.vision_start_token_id).nonzero(as_tuple=True)[0]\n",
    "            ends = (input_ids[b] == self.vision_end_token_id).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            # For each start token, mark the positions up to the corresponding end token\n",
    "            for i in range(len(starts)):\n",
    "                start_pos = starts[i]\n",
    "                # Find the corresponding end position or use sequence length if not found\n",
    "                end_pos = seq_length\n",
    "                for end_idx in ends:\n",
    "                    if end_idx > start_pos:\n",
    "                        end_pos = end_idx\n",
    "                        break\n",
    "                \n",
    "                # Mark the positions between start and end as vision positions\n",
    "                # (not including the start token itself, but including positions up to end token)\n",
    "                if start_pos + 1 < seq_length:\n",
    "                    is_vision_position[b, start_pos+1:min(end_pos+1, seq_length)] = True\n",
    "        \n",
    "        return is_vision_position\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        pixel_values: Optional[torch.Tensor] = None,\n",
    "        pixel_values_videos: Optional[torch.FloatTensor] = None,\n",
    "        image_grid_thw: Optional[torch.LongTensor] = None,\n",
    "        video_grid_thw: Optional[torch.LongTensor] = None,\n",
    "        rope_deltas: Optional[torch.LongTensor] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        second_per_grid_ts: Optional[torch.Tensor] = None,\n",
    "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "        \"\"\"\n",
    "        Forward pass for the any-to-any model that can generate both text and vision tokens.\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # Store original input_embeds for vision loss calculation\n",
    "        original_inputs_embeds = None\n",
    "        \n",
    "        # Process inputs and prepare embeddings\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.model.embed_tokens(input_ids)\n",
    "            \n",
    "            # Process image inputs if available\n",
    "            if pixel_values is not None:\n",
    "                pixel_values = pixel_values.type(self.visual.dtype)\n",
    "                image_embeds = self.visual(pixel_values, grid_thw=image_grid_thw)\n",
    "                mask = (input_ids == self.config.image_token_id).unsqueeze(-1).expand_as(inputs_embeds)\n",
    "                inputs_embeds = inputs_embeds.masked_scatter(\n",
    "                    mask, image_embeds.to(inputs_embeds.device, inputs_embeds.dtype)\n",
    "                )\n",
    "            \n",
    "            # Process video inputs if available\n",
    "            if pixel_values_videos is not None:\n",
    "                pixel_values_videos = pixel_values_videos.type(self.visual.dtype)\n",
    "                video_embeds = self.visual(pixel_values_videos, grid_thw=video_grid_thw)\n",
    "                mask = (input_ids == self.config.video_token_id).unsqueeze(-1).expand_as(inputs_embeds)\n",
    "                inputs_embeds = inputs_embeds.masked_scatter(\n",
    "                    mask, video_embeds.to(inputs_embeds.device, inputs_embeds.dtype)\n",
    "                )\n",
    "                \n",
    "            if attention_mask is not None:\n",
    "                attention_mask = attention_mask.to(inputs_embeds.device)\n",
    "            \n",
    "            # Save the original inputs_embeds for use in loss calculation\n",
    "            # Using detach() to prevent gradient flow through the target values\n",
    "            original_inputs_embeds = inputs_embeds.clone().detach()\n",
    "\n",
    "        # Handle position_ids and rope_deltas as in the original model\n",
    "        if position_ids is None and (attention_mask is None or attention_mask.ndim == 2):\n",
    "            if (\n",
    "                (cache_position is not None and cache_position[0] == 0)\n",
    "                or self.rope_deltas is None\n",
    "                or (past_key_values is None or past_key_values.get_seq_length() == 0)\n",
    "            ):\n",
    "                position_ids, rope_deltas = self.get_rope_index(\n",
    "                    input_ids,\n",
    "                    image_grid_thw,\n",
    "                    video_grid_thw,\n",
    "                    second_per_grid_ts,\n",
    "                    attention_mask,\n",
    "                )\n",
    "                self.rope_deltas = rope_deltas\n",
    "            else:\n",
    "                batch_size, seq_length, _ = inputs_embeds.shape\n",
    "                delta = (\n",
    "                    (cache_position[0] + self.rope_deltas).to(inputs_embeds.device)\n",
    "                    if cache_position is not None\n",
    "                    else 0\n",
    "                )\n",
    "                position_ids = torch.arange(seq_length, device=inputs_embeds.device)\n",
    "                position_ids = position_ids.view(1, -1).expand(batch_size, -1)\n",
    "                if cache_position is not None:\n",
    "                    delta = delta.repeat_interleave(batch_size // delta.shape[0], dim=0)\n",
    "                position_ids = position_ids.add(delta)\n",
    "                position_ids = position_ids.unsqueeze(0).expand(3, -1, -1)\n",
    "\n",
    "        # Forward pass through the LLM\n",
    "        outputs = self.model(\n",
    "            input_ids=None,\n",
    "            position_ids=position_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            cache_position=cache_position,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        \n",
    "        # Identify positions where we need to predict vision tokens\n",
    "        vision_positions = None\n",
    "        if input_ids is not None:\n",
    "            vision_positions = self.identify_vision_positions(input_ids)\n",
    "        print(f\"vision_positions: {vision_positions}\")\n",
    "        \n",
    "        # Get text logits for the entire sequence\n",
    "        text_logits = self.lm_head(hidden_states)\n",
    "        print(f\"text_logits.shape: {text_logits.shape}\")\n",
    "        \n",
    "        # Get vision predictions for the entire sequence\n",
    "        vision_predictions = self.vision_head(hidden_states)\n",
    "        print(f\"vision_predictions.shape: {vision_predictions.shape}\")\n",
    "        \n",
    "        # Calculate loss (if in training mode)\n",
    "        loss = None\n",
    "        \n",
    "        # If labels are not provided but we have input_ids, generate them\n",
    "        if labels is None and input_ids is not None:\n",
    "            labels = self.generate_labels(input_ids, vision_positions)\n",
    "            \n",
    "        if labels is not None:\n",
    "            # Initialize loss\n",
    "            loss = 0.0\n",
    "            \n",
    "            # 1. Calculate text loss (cross-entropy)\n",
    "            text_logits_float = text_logits.float()\n",
    "            \n",
    "            # Shift logits and labels for next-token prediction\n",
    "            shift_logits = text_logits_float[..., :-1, :].contiguous()\n",
    "            print(f\"shift_logits: {shift_logits}, shape: {shift_logits.shape}\")\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            print(f\"shift_labels: {shift_labels}, shape: {shift_labels.shape}\")\n",
    "            \n",
    "            # Mask out vision positions in labels to avoid computing text loss for them\n",
    "            if vision_positions is not None:\n",
    "                # Shift vision positions to align with shifted labels\n",
    "                shift_vision_positions = vision_positions[..., 1:].contiguous()\n",
    "                shift_labels = shift_labels.masked_fill(shift_vision_positions, -100)\n",
    "            \n",
    "            # Calculate cross-entropy loss for text positions\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            shift_logits = shift_logits.view(-1, self.config.vocab_size)\n",
    "            shift_labels = shift_labels.view(-1)\n",
    "            shift_labels = shift_labels.to(shift_logits.device)\n",
    "            text_loss = loss_fct(shift_logits, shift_labels)\n",
    "            loss += text_loss\n",
    "            print(f\"text_loss: {text_loss}, shape: {text_loss.shape}\")\n",
    "            \n",
    "            # 2. Calculate vision loss (MSE or cosine similarity)\n",
    "            if vision_positions is not None and vision_positions.any() and original_inputs_embeds is not None:\n",
    "                # Get the shifted vision positions for next-token prediction\n",
    "                shift_vision_positions = vision_positions[..., :-1].contiguous()\n",
    "                \n",
    "                if shift_vision_positions.any():\n",
    "                    # Get predictions and targets for vision positions\n",
    "                    # Predictions: what our vision head predicts for the next position\n",
    "                    # Targets: the actual embeddings from the input at the next position\n",
    "                    \n",
    "                    # Get predicted vision embeddings (from current positions)\n",
    "                    pred_vision_embeds = vision_predictions[..., :-1, :][shift_vision_positions]\n",
    "                    \n",
    "                    # Get target embeddings (from next positions in original_inputs_embeds)\n",
    "                    target_vision_embeds = original_inputs_embeds[..., 1:, :][shift_vision_positions]\n",
    "                    \n",
    "                    # Calculate MSE loss between predicted and target vision embeddings\n",
    "                    vision_loss = F.mse_loss(\n",
    "                        pred_vision_embeds, \n",
    "                        target_vision_embeds.to(pred_vision_embeds.dtype)\n",
    "                    )\n",
    "                    \n",
    "                    # Alternative: Cosine similarity loss\n",
    "                    # vision_loss = 1 - F.cosine_similarity(\n",
    "                    #     pred_vision_embeds, \n",
    "                    #     target_vision_embeds.to(pred_vision_embeds.dtype), \n",
    "                    #     dim=-1\n",
    "                    # ).mean()\n",
    "                    \n",
    "                    loss += vision_loss\n",
    "                    print(f\"vision_loss: {vision_loss}, shape: {vision_loss.shape}\")\n",
    "\n",
    "        # Return the appropriate output format\n",
    "        if not return_dict:\n",
    "            output = (text_logits,) + outputs[1:]\n",
    "            return (loss,) + output if loss is not None else output\n",
    "        \n",
    "        return Qwen2_5_VLCausalLMOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=text_logits,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "            rope_deltas=self.rope_deltas,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of your custom AnyToAnyQwen2_5_VL class\n",
    "model = AnyToAnyQwen2_5_VL(base_model.config)\n",
    "\n",
    "# Transfer the weights from the original model to your custom model\n",
    "model.load_state_dict(base_model.state_dict(), strict=False)\n",
    "\n",
    "model.setup_vision_head()\n",
    "\n",
    "model = model.to('cuda')\n",
    "model = model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(profile=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vision_positions: tensor([[False, False, False,  ..., False, False, False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1076, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1076, 2048])\n",
      "labels: tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), shape: torch.Size([1, 1076])\n",
      "vision_positions: tensor([[False, False, False,  ..., False, False, False]], device='cuda:0'), shape: torch.Size([1, 1076])\n",
      "shift_logits: tensor([[[10.5625, 18.8750, 18.0000,  ...,  8.5000,  8.5000,  8.5000],\n",
      "         [ 9.8750, 14.8125,  9.0000,  ...,  6.7812,  6.7812,  6.7812],\n",
      "         [15.6875, 18.5000, 21.1250,  ...,  7.1875,  7.1875,  7.1875],\n",
      "         ...,\n",
      "         [ 3.8906, -2.0469, -6.6250,  ...,  1.9844,  1.9844,  1.9844],\n",
      "         [10.8125, 12.8125,  9.8750,  ...,  6.0625,  6.0625,  6.0625],\n",
      "         [18.3750, 17.7500, 15.5625,  ...,  6.9062,  6.9062,  6.9375]]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>), shape: torch.Size([1, 1075, 151936])\n",
      "shift_labels: tensor([[  8948,    198,   2610,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), shape: torch.Size([1, 1075])\n",
      "text_loss: 9.279048919677734, shape: torch.Size([])\n",
      "vision_loss: 4.59375, shape: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "out = model(input_ids = inputs['input_ids'], pixel_values = inputs['pixel_values'], attention_mask =\n",
    "inputs['attention_mask'], image_grid_thw = inputs['image_grid_thw'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output items:\n",
      "loss: shape=torch.Size([]), value=13.872798919677734\n",
      "logits: shape=torch.Size([1, 1076, 151936]), value=tensor([[[10.5625, 18.8750, 18.0000,  ...,  8.5000,  8.5000,  8.5000],\n",
      "         [ 9.8750, 14.8125,  9.0000,  ...,  6.7812,  6.7812,  6.7812],\n",
      "         [15.6875, 18.5000, 21.1250,  ...,  7.1875,  7.1875,  7.1875],\n",
      "         ...,\n",
      "         [10.8125, 12.8125,  9.8750,  ...,  6.0625,  6.0625,  6.0625],\n",
      "         [18.3750, 17.7500, 15.5625,  ...,  6.9062,  6.9062,  6.9375],\n",
      "         [15.8125, 18.3750, 18.0000,  ...,  6.5938,  6.5938,  6.5938]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>)\n",
      "past_key_values: <transformers.cache_utils.DynamicCache object at 0x7f1eca928b60>\n",
      "rope_deltas: shape=torch.Size([1, 1]), value=tensor([[-966]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Output items:\")\n",
    "for key, value in out.items():\n",
    "    if hasattr(value, 'shape'):\n",
    "        print(f\"{key}: shape={value.shape}, value={value}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vision_positions: tensor([[False, False, False,  ..., False, False, False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1076, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1076, 2048])\n",
      "labels: tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), shape: torch.Size([1, 1076])\n",
      "vision_positions: tensor([[False, False, False,  ..., False, False, False]], device='cuda:0'), shape: torch.Size([1, 1076])\n",
      "shift_logits: tensor([[[10.5625, 18.8750, 18.0000,  ...,  8.5000,  8.5000,  8.5000],\n",
      "         [ 9.8750, 14.8125,  9.0000,  ...,  6.7812,  6.7812,  6.7812],\n",
      "         [15.6875, 18.5000, 21.1250,  ...,  7.1875,  7.1875,  7.1875],\n",
      "         ...,\n",
      "         [ 3.8906, -2.0469, -6.6250,  ...,  1.9844,  1.9844,  1.9844],\n",
      "         [10.8125, 12.8125,  9.8750,  ...,  6.0625,  6.0625,  6.0625],\n",
      "         [18.3750, 17.7500, 15.5625,  ...,  6.9062,  6.9062,  6.9375]]],\n",
      "       device='cuda:0'), shape: torch.Size([1, 1075, 151936])\n",
      "shift_labels: tensor([[  8948,    198,   2610,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), shape: torch.Size([1, 1075])\n",
      "text_loss: 9.279048919677734, shape: torch.Size([])\n",
      "vision_loss: 4.59375, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[95456]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[0]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[6771]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[594]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1438]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1495]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[279]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2661]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35972]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[23393]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3019]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[553]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3019]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[382]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[14374]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[5512]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[16378]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[510]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[78045]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[282]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2075]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[8]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[284]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[396]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15159]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[30529]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[384]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[87210]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[83]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2359]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1242]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15159]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[77]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[28]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[16]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15940]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[59]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2359]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11520]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[45340]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[86167]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15170]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[77]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[0]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11035]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1291]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[9139]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[90]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[77]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[488]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[384]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[83]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1291]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[8]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7594]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[488]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[90]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[76]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15170]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[59]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[26888]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[58]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[18]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15370]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[59]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1242]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15159]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[73]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[28]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[45340]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[47822]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[73]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3417]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[96065]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[73]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[41295]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[75542]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2533]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[16]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[13]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3070]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[66164]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3660]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[25]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1019]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[256]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[58]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[396]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15159]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[30529]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[384]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[87210]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[83]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2359]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1242]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15159]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[77]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[28]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[16]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15940]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[59]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2359]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11520]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[45340]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[86167]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15170]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[77]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[0]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11035]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1291]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[9139]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[90]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[77]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[488]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[384]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[83]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1291]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[8]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7594]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2533]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[256]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1096]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[25098]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17601]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[458]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[23809]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[4013]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[4766]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[279]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[25098]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[13]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[576]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[4647]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17767]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[384]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[87210]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[83]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[8]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[374]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[264]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[48568]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[729]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[892]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[374]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1632]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[21309]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[369]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1181]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[5888]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[304]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[18927]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[10126]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[323]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[13142]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[13]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[576]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[4013]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[4766]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[279]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[25098]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[374]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[264]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2629]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[315]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3793]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15860]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17767]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15940]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[8]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[323]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17767]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[384]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[83]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3593]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[13]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3070]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15666]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3660]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[25]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1019]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[256]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[58]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[90]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[76]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15170]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[59]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[26888]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[58]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[18]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15370]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[59]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1242]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15159]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[73]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[28]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[45340]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[47822]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[73]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3417]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[96065]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[73]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[41295]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[75542]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2533]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[256]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1096]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[949]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17601]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[264]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[4013]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2629]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[4766]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[264]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[23739]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3704]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[13]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[576]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[4013]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17767]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1242]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15159]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[73]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[28]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[45340]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[47822]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[73]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3417]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[96065]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[73]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[41295]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[8]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[374]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[264]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1632]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[21309]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[4013]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[14461]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[369]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[279]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17071]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[65]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7762]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[75259]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[729]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17767]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[66]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[9267]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2075]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[8]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[568]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15277]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[279]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7493]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15491]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[9606]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[311]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[510]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[256]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[58]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[90]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[76]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15170]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[59]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[26888]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[58]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[18]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15370]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[59]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[66]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[9267]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2075]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[52731]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2533]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[14374]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[10440]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[16378]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[510]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[78045]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[396]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15159]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[30529]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[384]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[87210]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[83]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2359]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1242]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15159]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[77]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[28]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[16]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15940]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[59]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2359]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11520]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[37018]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[45340]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[86167]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15170]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[77]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[0]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11035]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1291]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[9139]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[90]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[77]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[488]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[384]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[83]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1291]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[8]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7594]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2533]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1986]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7493]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[374]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[19516]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[311]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[279]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1156]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7493]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[3650]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[369]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[279]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2086]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[949]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[892]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[374]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[7402]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[13]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15277]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[11]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[432]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15491]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[9606]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[311]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[510]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[78045]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[396]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[15159]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[30529]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[35702]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[258]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[36958]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[384]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[87210]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[83]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[61]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[17]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[92]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[1124]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "vision_positions: tensor([[False]], device='cuda:0')\n",
      "text_logits.shape: torch.Size([1, 1, 151936])\n",
      "vision_predictions.shape: torch.Size([1, 1, 2048])\n",
      "labels: tensor([[2359]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "vision_positions: tensor([[False]], device='cuda:0'), shape: torch.Size([1, 1])\n",
      "shift_logits: tensor([], device='cuda:0', size=(1, 0, 151936)), shape: torch.Size([1, 0, 151936])\n",
      "shift_labels: tensor([], device='cuda:0', size=(1, 0), dtype=torch.int64), shape: torch.Size([1, 0])\n",
      "text_loss: nan, shape: torch.Size([])\n",
      "[\"Certainly! Let's break down the given mathematical expressions step by step.\\n\\n### First Expression:\\n\\\\[ f(x) = \\\\int_{-\\\\infty}^{\\\\infty} e^{-t^2} \\\\left( \\\\sum_{n=1}^{\\\\infty} \\\\frac{\\\\sin\\\\left(\\\\frac{x^n}{n!}\\\\right)}{n^2 + e^t} \\\\right) dt + \\\\frac{m}{\\\\sqrt[3]{\\\\sum_{j=0}^{\\\\infty} \\\\frac{x^{2j}}{(2j)!}}} \\\\]\\n\\n1. **Integral Part:**\\n   \\\\[ \\\\int_{-\\\\infty}^{\\\\infty} e^{-t^2} \\\\left( \\\\sum_{n=1}^{\\\\infty} \\\\frac{\\\\sin\\\\left(\\\\frac{x^n}{n!}\\\\right)}{n^2 + e^t} \\\\right) dt \\\\]\\n\\n   This integral involves an infinite series inside the integral. The term \\\\( e^{-t^2} \\\\) is a Gaussian function, which is well-known for its properties in probability theory and statistics. The series inside the integral is a sum of terms involving \\\\( \\\\sin \\\\) and \\\\( e^t \\\\).\\n\\n2. **Second Part:**\\n   \\\\[ \\\\frac{m}{\\\\sqrt[3]{\\\\sum_{j=0}^{\\\\infty} \\\\frac{x^{2j}}{(2j)!}}} \\\\]\\n\\n   This part involves a series sum inside a cube root. The series \\\\( \\\\sum_{j=0}^{\\\\infty} \\\\frac{x^{2j}}{(2j)!} \\\\) is a well-known series expansion for the hyperbolic cosine function, \\\\( \\\\cosh(x) \\\\). Therefore, the expression simplifies to:\\n   \\\\[ \\\\frac{m}{\\\\sqrt[3]{\\\\cosh(x)}} \\\\]\\n\\n### Second Expression:\\n\\\\[ \\\\int_{-\\\\infty}^{\\\\infty} e^{-t^2} \\\\left( \\\\sum_{n=1}^{\\\\infty} \\\\frac{\\\\sin\\\\left(\\\\frac{x^n}{n!}\\\\right)}{n^2 + e^t} \\\\right) dt \\\\]\\n\\nThis expression is identical to the first expression except for the second part, which is missing. Therefore, it simplifies to:\\n\\\\[ \\\\int_{-\\\\infty}^{\\\\infty} e^{-t^2} \\\\left(\"]\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(**inputs, max_new_tokens=512)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
